{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647ec16c-b1ec-486f-8539-8b88b4006efd",
   "metadata": {},
   "source": [
    "# Answer 1\n",
    "Lasso regression is a regularization technique. It is used over regression methods for a more accurate prediction. This model uses shrinkage. Shrinkage is where data values are shrunk towards a central point as the mean.\n",
    "Lasso is a modification of linear regression, where the model is penalized for the sum of absolute values of the weights. Thus, the absolute values of weight will be (in general) reduced, and many will tend to be zeros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f883a7f-3c35-4266-a43e-635236deda2a",
   "metadata": {},
   "source": [
    "# Answer 2\n",
    "Advantages of LASSO regression\n",
    "\n",
    "Automatic features selection\n",
    "\n",
    "The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not be included on its own.\n",
    "\n",
    "Reduced overfitting \n",
    "\n",
    "Another advantage of a LASSO regression is that the L1 penalty that is added to the model helps to prevent the model from overfitting. This makes intuitive sense because when the model sets feature coefficients to zero and effectively removes features from the model, model complexity decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d181634-35aa-468e-b403-255b280e61da",
   "metadata": {},
   "source": [
    "# Answer 3\n",
    "Lasso regression produces a model that is easy to interpret, as it includes only a subset of the predictors and assigns zero coefficients to the irrelevant ones. This can help in understanding the relationships between the predictors and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd21c6f8-1dcd-4cca-b833-d7eca37671f1",
   "metadata": {},
   "source": [
    "# Answer 4\n",
    "A tuning parameter (λ), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df1c31-fe3b-473b-91b0-3bc263eca20e",
   "metadata": {},
   "source": [
    "# Answer 5\n",
    "NO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ababd-9e8d-4e5c-a494-dfee63ba771a",
   "metadata": {},
   "source": [
    "# Answer 6\n",
    "## Ridge Regression\n",
    "\n",
    "The penalty term is the sum of the squares of the coefficients (L2 regularization).\t\n",
    "\n",
    "Shrinks the coefficients but doesn’t set any coefficient to zero.\t\n",
    "\n",
    "Helps to reduce overfitting by shrinking large coefficients.\t\n",
    "\n",
    "Works well when there are a large number of features.\t\n",
    "\n",
    "Performs “soft thresholding” of coefficients.\t\n",
    "\n",
    "\n",
    "## Lasso Regression\n",
    "\n",
    "The penalty term is the sum of the absolute values of the coefficients (L1 regularization).\n",
    "\n",
    "Can shrink some coefficients to zero, effectively performing feature selection.\n",
    "\n",
    "Helps to reduce overfitting by shrinking and selecting features with less importance.\n",
    "\n",
    "Works well when there are a small number of features.\n",
    "\n",
    "Performs “hard thresholding” of coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cc943-9341-47d8-927e-991cb173f373",
   "metadata": {},
   "source": [
    "# Answer 7\n",
    "Yes\n",
    "\n",
    "Lasso regression is a linear regression technique with L1 prior as a regularize. The idea is to reduce the multicollinearity by regularization by reducing the coefficients of the feature that are multicollinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184cd673-4f0c-4c49-9eaf-4154077aaa99",
   "metadata": {},
   "source": [
    "# Answer 8\n",
    "In ridge regression for large values of lambda the parameters tend to zero while in lasso regression, the parameters can be equal to zero.\n",
    "\n",
    "For lasso regression, the alpha value is 1. The output is the best cross-validated lambda, which comes out to be 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad8c84-d6a8-4bf0-bee6-5fc1120a8e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56768ed3-9346-4b82-a06e-2ff186bea0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
